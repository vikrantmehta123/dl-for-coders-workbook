{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNm5zh1nGoTjP9tyeOTGx3s"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# NLP Using Fastai"
      ],
      "metadata": {
        "id": "CewKjyD196o_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "R3tdE-ay93gR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4a77b2ab-1a16-4f16-f62b-486d69863f9d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/719.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m716.8/719.8 kB\u001b[0m \u001b[31m25.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m719.8/719.8 kB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/480.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m480.6/480.6 kB\u001b[0m \u001b[31m32.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/116.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.3/179.3 kB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m52.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "! [ -e /content ] && pip install -Uqq fastbook\n",
        "import fastbook"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from fastbook import *\n",
        "from IPython.display import display,HTML"
      ],
      "metadata": {
        "id": "62j5g5ov-A7L"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Get the IMDB Data"
      ],
      "metadata": {
        "id": "mXQarglR64V_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from fastai.text.all import *\n",
        "path = untar_data(URLs.IMDB)\n",
        "path"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "7U9xvKYV4eXM",
        "outputId": "a63f0c97-6c95-43a0-cd65-55b4fc97d337"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      <progress value='144441344' class='' max='144440600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      100.00% [144441344/144440600 00:03&lt;00:00]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Path('/root/.fastai/data/imdb')"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "files = get_text_files(path, folders = ['train', 'test', 'unsup'])\n",
        "files"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NBgUxEZS4fnD",
        "outputId": "82f6a091-b3e3-49e5-894e-defc0f8624a9"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(#100000) [Path('/root/.fastai/data/imdb/unsup/34391_0.txt'),Path('/root/.fastai/data/imdb/unsup/7307_0.txt'),Path('/root/.fastai/data/imdb/unsup/22454_0.txt'),Path('/root/.fastai/data/imdb/unsup/40514_0.txt'),Path('/root/.fastai/data/imdb/unsup/48062_0.txt'),Path('/root/.fastai/data/imdb/unsup/7455_0.txt'),Path('/root/.fastai/data/imdb/unsup/2827_0.txt'),Path('/root/.fastai/data/imdb/unsup/41382_0.txt'),Path('/root/.fastai/data/imdb/unsup/39685_0.txt'),Path('/root/.fastai/data/imdb/unsup/9323_0.txt')...]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "txt = files[0].open().read()\n",
        "txt[:75]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "rvrybGx-4lFZ",
        "outputId": "fc7919f8-9636-467c-a795-39329813fb5d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'I do not blame the game, but myself, for losing hundreds of hours that with'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tokenization"
      ],
      "metadata": {
        "id": "vnjJIzZc67jl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Word Level Tokenization"
      ],
      "metadata": {
        "id": "z0k7nk4K7BEF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "spacy = WordTokenizer()\n",
        "tokens = first(spacy([txt]))\n",
        "coll_repr(tokens, 30)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "nXlN3_dw5GS-",
        "outputId": "b9dfdf71-f11b-421c-83ec-2d7ef85632c9"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"(#385) ['I','do','not','blame','the','game',',','but','myself',',','for','losing','hundreds','of','hours','that','with','ease','could','have','been','spent','doing','something','constructive','/','more','fun','.','It'...]\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = Tokenizer(spacy)\n",
        "coll_repr(tokenizer(txt), 31)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "depG46dC5hNu",
        "outputId": "5f9a9c7d-2784-4673-8bc5-a3c761cd3a70"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"(#408) ['xxbos','i','do','not','blame','the','game',',','but','myself',',','for','losing','hundreds','of','hours','that','with','ease','could','have','been','spent','doing','something','constructive','/','more','fun','.','xxmaj'...]\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "defaults.text_proc_rules"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wiHJ-fJs5s5l",
        "outputId": "1601bc5d-ecee-4da8-c0f3-a2ec86e0c985"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<function fastai.text.core.fix_html(x)>,\n",
              " <function fastai.text.core.replace_rep(t)>,\n",
              " <function fastai.text.core.replace_wrep(t)>,\n",
              " <function fastai.text.core.spec_add_spaces(t)>,\n",
              " <function fastai.text.core.rm_useless_spaces(t)>,\n",
              " <function fastai.text.core.replace_all_caps(t)>,\n",
              " <function fastai.text.core.replace_maj(t)>,\n",
              " <function fastai.text.core.lowercase(t, add_bos=True, add_eos=False)>]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Subword Level Tokenization"
      ],
      "metadata": {
        "id": "vT3G2A8h7EJ4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "txts = L(o.open().read() for o in files[:2000])"
      ],
      "metadata": {
        "id": "ybeOabM-5wLy"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def subword(sz):\n",
        "    sp = SubwordTokenizer(vocab_sz=sz)\n",
        "    sp.setup(txts)\n",
        "    return ' '.join(first(sp([txt])))"
      ],
      "metadata": {
        "id": "GM9hS14S6SYI"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Larger vocabulary size means a sentence will be represented by fewer tokens, whereas smaller vocabulary size means that a sentence will require more tokens to be represented. Picking a subword vocab size represents a compromise: a larger vocab means fewer tokens per sentence, which means faster training, less memory, and less state for the model to remember; but on the downside, it means larger embedding matrices, which require more data to learn."
      ],
      "metadata": {
        "id": "3SkqdewL6o2V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "subword(1000)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        },
        "id": "0NYjdCoz6n7Q",
        "outputId": "e7d81ea0-5796-4c21-a750-3b6363db3cfa"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'▁I ▁do ▁not ▁b la me ▁the ▁game , ▁but ▁myself , ▁for ▁lo s ing ▁ h un d r ed s ▁of ▁ho ur s ▁that ▁with ▁e a se ▁could ▁have ▁been ▁sp ent ▁do ing ▁something ▁con st r u c t ive / mo re ▁fun . ▁It ▁to ok ▁me ▁a ▁good ▁two ▁years ▁before ▁real iz ing ▁the ▁complete ▁no n s en se ▁of ▁actually ▁de vo ting ▁even ▁a ▁minute ▁to ▁this ▁game , ▁and ▁at ▁the ▁point ▁of ▁re co g n iz ing ▁this ▁fact ▁it ▁to ok ▁me ▁ less ▁than ▁no ▁time ▁to ▁st op ▁play ing ▁for ▁good . ▁W h y ▁is ▁it ▁no n s en se ? ▁< br ▁/> < br ▁/> The ▁game ▁is ▁ho r ri b ly ▁line ar . ▁P la y ▁it ▁through ▁with ▁one ▁character ▁and ▁you \\' ve ▁ex p l or ed ▁all ▁there ▁is ▁to ▁it . ▁ Q u est s ▁come ▁in ▁3 ▁vari ation s ▁( \" W ow ! \" ▁is ▁pretty ▁far ▁from ▁the ▁first ▁thought ▁that ▁come s ▁to ▁mind ▁when ▁see ing ▁that ). ▁Ch ar act er ▁develop ment ▁come s ▁to ▁a ▁ha l t ▁at ▁level ▁2 0 , ▁after ▁which ▁little ▁hope ▁is ▁in ▁s ight . ▁A t ▁to p ▁level ▁all ▁you ▁can ▁do ▁to ▁f ur ther ▁b u il d ▁up ▁your ▁character ▁is ▁to ▁gr in d , ▁gr in d , ▁and ▁gr in d ▁some ▁more ▁for ▁e qui p ment ▁that ▁is ▁s light ly ▁better ▁than ▁what ▁you ▁already ▁have . ▁Ch ar act er ▁ski ll s ▁are ▁de ad ▁and ▁st al e . ▁E x p l or ing ▁no n - ex ist ent . ▁Ch ar act er ▁pro g re s s ▁is ▁lo st . ▁P v P ▁is ▁another ▁mean s ▁to ▁ d ra in ▁you ▁of ▁yet ▁another ▁couple ▁of ▁ h un d r ed ▁ho ur s ▁and ▁ d re ad ful ly ▁pre d ic t ive ▁un less ▁you ▁are ▁a ▁di m w it , ▁re ach ing ▁ ne ▁p l us ▁ ul t ra ▁mean ing ▁( t ake ▁a ▁w il d ▁guess ) ▁better ▁e qui p ment . < br ▁/> < br ▁/> A t ▁level ▁ 7 0 ▁ _ ever y th ing _ ▁bo il s ▁down ▁to ▁get ting ▁better ▁e qui p ment ? ▁For ▁what ▁p ur po se ? ▁To ▁be ▁ able ▁to ▁get ▁even ▁better ▁e qui p ment . ▁I ▁would ▁ch uck le ▁if ▁I ▁did ▁not ▁feel ▁s or ry ▁for ▁everyone ▁still ▁play ing . ▁The ▁e c on om ic ▁as p ect ▁of ▁the ▁game ▁is ▁la ck ing ▁in ▁so ▁many ▁are as ▁it \\' s ▁pa in ful ▁to ▁even ▁think ▁about ▁it . < br ▁/> < br ▁/> S ure , ▁there ▁are ▁a ▁few ▁pro s ▁as ▁well . ▁P la y ing ▁with ▁your ▁friend s ▁is ▁fun ▁for ▁a ▁while , ▁but ▁there ▁are ▁better ▁and ▁more ▁in t r ic ate ▁game s ▁that ▁actually ▁give ▁something ▁in ▁re t ur n ▁while ▁do ing ▁so . ▁C le ar ing ▁an ▁end - g am e ▁in st ance ▁is ▁fun ▁the ▁first ▁time , ▁after ▁which ▁it ▁get s ▁re pe t it ive . ▁S am e ▁with ▁P v P . ▁This ▁game ▁is ▁f la w ed ▁in ▁so ▁many ▁way s ▁it \\' s ▁a ▁wonder ▁that ▁people ▁continu e ▁to ▁play ▁it . < br ▁/> < br ▁/> W ow ▁is ▁a ▁ho a x ▁and ▁you \\' re ▁all ▁being ▁ch e ated .'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "subword(200)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        },
        "id": "jkGuVHet6aOx",
        "outputId": "32c819de-1218-49f0-bfda-f3d7b239b095"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'▁I ▁do ▁not ▁b la m e ▁the ▁ g a m e , ▁but ▁ m y s e l f , ▁for ▁lo s ing ▁ h un d re d s ▁of ▁ h o ur s ▁that ▁with ▁ e a s e ▁co u l d ▁have ▁be en ▁s p ent ▁do ing ▁s o m e th ing ▁co n st r u c t i ve / m o re ▁f un . ▁I t ▁to o k ▁ m e ▁a ▁ g o o d ▁ t w o ▁ y e ar s ▁be f o re ▁ re al i z ing ▁the ▁co m p le t e ▁ n on s en s e ▁of ▁ act u al ly ▁de v o t ing ▁ e ve n ▁a ▁ m in u t e ▁to ▁this ▁ g a m e , ▁and ▁a t ▁the ▁p o in t ▁of ▁ re c o g n i z ing ▁this ▁f act ▁it ▁to o k ▁ m e ▁ le s s ▁ th an ▁ n o ▁ t i m e ▁to ▁ st o p ▁p la y ing ▁for ▁ g o o d . ▁ W h y ▁is ▁it ▁ n on s en s e ? ▁ < br ▁/> < br ▁/> T h e ▁ g a m e ▁is ▁ h or ri b ly ▁ l in e ar . ▁ P la y ▁it ▁ th ro u g h ▁with ▁on e ▁ ch ar act er ▁and ▁you \\' ve ▁ e x p l or ed ▁a ll ▁the re ▁is ▁to ▁it . ▁ Q u e st s ▁co m e ▁in ▁ 3 ▁ v ar i at i on s ▁ ( \" W o w ! \" ▁is ▁p re t t y ▁f ar ▁f ro m ▁the ▁f ir st ▁ th o u g h t ▁that ▁co m es ▁to ▁ m in d ▁w h en ▁see ing ▁that ) . ▁ C h ar act er ▁de ve l o p m ent ▁co m es ▁to ▁a ▁ h al t ▁a t ▁ le ve l ▁ 2 0 , ▁a f ter ▁w h i ch ▁ li t t le ▁ h o p e ▁is ▁in ▁s i g h t . ▁A t ▁to p ▁ le ve l ▁a ll ▁you ▁ca n ▁do ▁to ▁f ur th er ▁b u i l d ▁ u p ▁you r ▁ ch ar act er ▁is ▁to ▁ g ri n d , ▁ g ri n d , ▁and ▁ g ri n d ▁s o m e ▁mo re ▁for ▁ e q u i p m ent ▁that ▁is ▁s li g h t ly ▁be t ter ▁ th an ▁w h at ▁you ▁ al re a d y ▁have . ▁ C h ar act er ▁s k i ll s ▁a re ▁de a d ▁and ▁ st al e . ▁ E x p l or ing ▁ n on - e x i st ent . ▁ C h ar act er ▁p ro g re s s ▁is ▁lo st . ▁ P v P ▁is ▁ an o th er ▁ m e an s ▁to ▁ d ra in ▁you ▁of ▁ y e t ▁ an o th er ▁co u p le ▁of ▁ h un d re d ▁ h o ur s ▁and ▁ d re a d f u ll y ▁p re d ic t i ve ▁ un le s s ▁you ▁a re ▁a ▁di m w it , ▁ re a ch ing ▁ n e ▁p l u s ▁ u l t ra ▁ m e an ing ▁ ( t a k e ▁a ▁w i l d ▁ g u es s ) ▁be t ter ▁ e q u i p m ent . < br ▁/> < br ▁/> A t ▁ le ve l ▁ 7 0 ▁ _ e ver y th ing _ ▁b o i l s ▁do w n ▁to ▁ g e t t ing ▁be t ter ▁ e q u i p m ent ? ▁ F or ▁w h at ▁p ur p o s e ? ▁ T o ▁be ▁a b le ▁to ▁ g e t ▁ e ve n ▁be t ter ▁ e q u i p m ent . ▁I ▁w o u l d ▁ ch u ck le ▁ i f ▁I ▁di d ▁not ▁f e e l ▁s or r y ▁for ▁ e ver y on e ▁ st i ll ▁p la y ing . ▁The ▁ e c on o m ic ▁a s p ect ▁of ▁the ▁ g a m e ▁is ▁ la ck ing ▁in ▁s o ▁ma n y ▁a re a s ▁it \\' s ▁p a in f u l ▁to ▁ e ve n ▁ th in k ▁a b o u t ▁it . < br ▁/> < br ▁/> S u re , ▁the re ▁a re ▁a ▁f e w ▁p ro s ▁a s ▁w e ll . ▁ P la y ing ▁with ▁you r ▁f ri en d s ▁is ▁f un ▁for ▁a ▁w h i le , ▁but ▁the re ▁a re ▁be t ter ▁and ▁mo re ▁in t ri c at e ▁ g a m es ▁that ▁ act u al ly ▁ g i ve ▁s o m e th ing ▁in ▁ re t ur n ▁w h i le ▁do ing ▁s o . ▁ C le ar ing ▁ an ▁ en d - g a m e ▁in st an ce ▁is ▁f un ▁the ▁f ir st ▁ t i m e , ▁a f ter ▁w h i ch ▁it ▁ g e t s ▁ re p e t it i ve . ▁S a m e ▁with ▁ P v P . ▁ T h i s ▁ g a m e ▁is ▁f la w ed ▁in ▁s o ▁ma n y ▁w a y s ▁it \\' s ▁a ▁w on d er ▁that ▁p e o p le ▁co n t in u e ▁to ▁p la y ▁it . < br ▁/> < br ▁/> W o w ▁is ▁a ▁ h o a x ▁and ▁you \\' re ▁a ll ▁be ing ▁ ch e at ed .'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Numericalization\n",
        "\n",
        "Map integers to tokens using Numericalize"
      ],
      "metadata": {
        "id": "PRcoz9Ki7UAH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "toks200 = txts[:200].map(tokenizer)\n",
        "toks200[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "loONtvUgC0QW",
        "outputId": "1fa4c6d9-2907-4722-df44-2dd1cb1bebf8"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(#408) ['xxbos','i','do','not','blame','the','game',',','but','myself'...]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num = Numericalize()\n",
        "num.setup(toks200)\n",
        "coll_repr(num.vocab,20)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "ayAsPY8oC9Em",
        "outputId": "412f2366-ec36-49ad-ef14-7888cabd2201"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"(#2136) ['xxunk','xxpad','xxbos','xxeos','xxfld','xxrep','xxwrep','xxup','xxmaj','the',',','.','and','a','of','to','is','it','in','i'...]\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num(toks200[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yHuejwGXDnZ2",
        "outputId": "b94052e1-caf5-4619-c676-f434e64c9672"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorText([   2,   19,   62,   36,    0,    9,  289,   10,   31,  483,   10,   26,    0,    0,   14,  754,   20,   30,    0,   99,   39,  105,  755,  484,  134,    0,  114,   63,  238,   11,    8,\n",
              "              17,  533,   83,   13,   69,  148,  150,  145,    0,    9,  427,  756,   14,  161,    0,   73,   13,  860,   15,   21,  289,   10,   12,   49,    9,  275,   14,    0,   21,  203,   17,\n",
              "             533,   83,  317,   91,   81,   84,   15,  757,  377,   26,   69,   11,    8,  206,   16,   17,  756,   85,   27,    8,    9,  289,   16, 1547,    0,   11,    8,  358,   17,  165,   30,\n",
              "              44,  113,   12,   33,  146,    0,   45,   54,   16,   15,   17,   11,    8,    0,  223,   18,  179,    0,   40,   23,  666,   51,   23,   16,  256,  175,   53,    9,  106,  230,   20,\n",
              "             239,   15,  341,   64,  276,   20,   38,   11,    8,  113, 1015,  239,   15,   13,    0,   49,  342,  758,   10,  109,   74,  102,  485,   16,   18,    0,   11,    8,   49,  343,  342,\n",
              "              45,   33,   78,   62,   15,  667, 1215,   77,  147,  113,   16,   15, 1548,   10, 1548,   10,   12, 1548,   58,   63,   26, 1016,   20,   16,  534,  135,   91,   65,   33,  452,   39,\n",
              "              11,    8,  113, 1017,   37,  378,   12,    0,   11,    8,    0,  668,   24, 1549,   11,    8,  113,    0,   16,  405,   11,    0,   16,  189,  669,   15,    0,   33,   14,  257,  189,\n",
              "             406,   14,    0,  754,   12,    0,    0,  759,   33,   37,   13,    0,   10,    0,    0, 1018,    0, 1216,   40,  167,   13,  586,  453,   38,  135, 1016,   11,   27,    8,   49,  342,\n",
              "            1550,    0,  307,    0,    0,  190,   15,  587,  135, 1016,   85,    8,   26,   65, 1217,   85,    8,   15,   43,  670,   15,  118,   73,  135, 1016,   11,   19,   71,    0,   57,   19,\n",
              "             119,   36,  180,  588,   26,  267,  149,  377,   11,    8,    9,    0, 1218,   14,    9,  289,   16, 1019,   18,   47,  153,    0,   17,   22, 1219,   15,   73,  124,   59,   17,   11,\n",
              "              27,    8,  240,   10,   54,   37,   13,  290,    0,   25,   76,   11,    8,  377,   30,  147,  344,   16,  238,   26,   13,  155,   10,   31,   54,   37,  135,   12,   63,    0, 1220,\n",
              "              20,  161,  224,  134,   18, 1551,  155,  484,   47,   11,    8,    0,   48,  168,   24,  289, 1552,   16,  238,    9,  106,   84,   10,  109,   74,   17,  217,    0,   11,    8,  162,\n",
              "              30,    0,   11,    8,   21,  289,   16,    0,   18,   47,  153, 1221,   17,   22,   13, 1020,   20,  116, 1021,   15,  358,   17,   11,   27,    8,  666,   16,   13,    0,   12,   33,\n",
              "             154,   45,  169,    0,   11])"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Passing Text as Batches"
      ],
      "metadata": {
        "id": "J2lL8Zo8GVCH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nums200 = toks200.map(num)"
      ],
      "metadata": {
        "id": "nNU2CG4tDsd0"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dl = LMDataLoader(nums200)\n",
        "x,y = first(dl)\n",
        "x.shape,y.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fzLpf-MmITCK",
        "outputId": "747eb8bb-f072-4847-83cd-d1288d373ebb"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([64, 72]), torch.Size([64, 72]))"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Independent Variable i.e. the input\n",
        "' '.join(num.vocab[o] for o in x[0][:20])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "EAHczH0zIYgE",
        "outputId": "d2045290-3d0c-4ad8-b5ab-f5a894fb82ee"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'xxbos i do not xxunk the game , but myself , for xxunk xxunk of hours that with xxunk could'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# The output- offset by one token\n",
        "' '.join(num.vocab[o] for o in y[0][:20])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "rcak9QIRIcn3",
        "outputId": "f398037c-230b-4c58-ddaa-0d3c850b6a7d"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'i do not xxunk the game , but myself , for xxunk xxunk of hours that with xxunk could have'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Language Modeling Using DataBlock"
      ],
      "metadata": {
        "id": "0uPBp3KnImiX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "get_imdb = partial(get_text_files, folders=['train', 'test', 'unsup'])\n",
        "\n",
        "dls_lm = DataBlock(\n",
        "    blocks=TextBlock.from_folder(path, is_lm=True),\n",
        "    get_items=get_imdb, splitter=RandomSplitter(0.1)\n",
        ").dataloaders(path, path=path, bs=128, seq_length=80)"
      ],
      "metadata": {
        "id": "m8rQQOlsIl8h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dls_lm.show_batch(max_n=2)"
      ],
      "metadata": {
        "id": "KVGpDNyyJRe6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 216
        },
        "outputId": "8e37f6fc-5554-46f2-e2b9-ac361ae4a608"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>text_</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>xxbos xxmaj never having seen an xxmaj oliver xxmaj stone film before , nor any films starring xxmaj eric xxmaj bogosian , i did n't know what to expect from this film . xxmaj having toyed with the idea of buying it for a while , i finally got it for free as a supplement with a xxmaj sunday newspaper and i was hugely impressed . \\n\\n xxmaj it tells the story</td>\n",
              "      <td>xxmaj never having seen an xxmaj oliver xxmaj stone film before , nor any films starring xxmaj eric xxmaj bogosian , i did n't know what to expect from this film . xxmaj having toyed with the idea of buying it for a while , i finally got it for free as a supplement with a xxmaj sunday newspaper and i was hugely impressed . \\n\\n xxmaj it tells the story of</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>mains have escaped the ruin of the city , and instinctively also veer away from the approaching xxmaj europeans . xxmaj they decide to \" go to the forest \" in hopes of living out their lives in peace , away from the destructiveness of all civilization . xxmaj the point in this case , is very bleak , since we can assume that they wo n't be able to escape no</td>\n",
              "      <td>have escaped the ruin of the city , and instinctively also veer away from the approaching xxmaj europeans . xxmaj they decide to \" go to the forest \" in hopes of living out their lives in peace , away from the destructiveness of all civilization . xxmaj the point in this case , is very bleak , since we can assume that they wo n't be able to escape no matter</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Finetuning The Language Model"
      ],
      "metadata": {
        "id": "TzJL1vCQJgFt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "learn = language_model_learner(\n",
        "    dls_lm, AWD_LSTM, drop_mult=0.3,\n",
        "    metrics=[accuracy, Perplexity()]).to_fp16()"
      ],
      "metadata": {
        "id": "E4TarLAOJjIW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "learn.fit_one_cycle(1, 2e-2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "id": "Fisj0X4TXSIB",
        "outputId": "ae35bd09-b4b1-4551-e705-0606b25daae5"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/fastai/callback/fp16.py:47: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  self.autocast,self.learn.scaler,self.scales = autocast(dtype=dtype),GradScaler(**self.kwargs),L()\n",
            "/usr/local/lib/python3.10/dist-packages/fastai/callback/fp16.py:47: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  self.autocast,self.learn.scaler,self.scales = autocast(dtype=dtype),GradScaler(**self.kwargs),L()\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>perplexity</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>4.007043</td>\n",
              "      <td>3.900225</td>\n",
              "      <td>0.300485</td>\n",
              "      <td>49.413586</td>\n",
              "      <td>23:13</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "learn.unfreeze()\n",
        "learn.fit_one_cycle(1, 2e-3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "id": "sns5QyPXXnZB",
        "outputId": "d26355af-d3b5-440f-ef0c-531930637eed"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/fastai/callback/fp16.py:47: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  self.autocast,self.learn.scaler,self.scales = autocast(dtype=dtype),GradScaler(**self.kwargs),L()\n",
            "/usr/local/lib/python3.10/dist-packages/fastai/callback/fp16.py:47: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  self.autocast,self.learn.scaler,self.scales = autocast(dtype=dtype),GradScaler(**self.kwargs),L()\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>perplexity</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>3.648069</td>\n",
              "      <td>3.646698</td>\n",
              "      <td>0.330425</td>\n",
              "      <td>38.347851</td>\n",
              "      <td>24:31</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "learn.save_encoder('finetuned')"
      ],
      "metadata": {
        "id": "RyjlC4XWa8nU"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Generating Movie Reviews Using the Finetuned Language Model"
      ],
      "metadata": {
        "id": "TdTfqanKX8nY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "TEXT = \"I liked this movie because\"\n",
        "N_WORDS = 40\n",
        "N_SENTENCES = 2\n",
        "preds = [learn.predict(TEXT, N_WORDS, temperature=0.75)\n",
        "         for _ in range(N_SENTENCES)]"
      ],
      "metadata": {
        "id": "yEJEnPa0YBbJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preds"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xH8jUZ34rcmP",
        "outputId": "508a5295-3cc2-4118-e14f-acbea2ee7302"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['i liked this movie because it was shot in a city in Mexico , with a very real backdrop . It freaked me out , i think . So much so , i was surprised to see that it had a very',\n",
              " \"i liked this movie because Santa Claus was just a boring flick . The plot was just plain stupid and the acting was so bad it 's laughable . i still ca n't stand this movie . It is n't even\"]"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creating the Classifier"
      ],
      "metadata": {
        "id": "_CM4z85pYQHx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dls_class = DataBlock(\n",
        "    blocks=(TextBlock.from_folder(path, vocab=dls_lm.vocab), CategoryBlock),\n",
        "    get_y=parent_label,\n",
        "    get_items=partial(get_text_files, folders=['train', 'test']),\n",
        "    splitter=GrandparentSplitter(valid_name='test')\n",
        ").dataloaders(path, path=path, bs=128, seq_len=72)"
      ],
      "metadata": {
        "id": "U4FoQWqfYPZC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dls_class.show_batch(max_n=3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "id": "jp_GcZJaZED2",
        "outputId": "3e77afda-63a0-49cd-910e-f616d75dd919"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>category</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>xxbos xxmaj match 1 : xxmaj tag xxmaj team xxmaj table xxmaj match xxmaj bubba xxmaj ray and xxmaj spike xxmaj dudley vs xxmaj eddie xxmaj guerrero and xxmaj chris xxmaj benoit xxmaj bubba xxmaj ray and xxmaj spike xxmaj dudley started things off with a xxmaj tag xxmaj team xxmaj table xxmaj match against xxmaj eddie xxmaj guerrero and xxmaj chris xxmaj benoit . xxmaj according to the rules of the match , both opponents have to go through tables in order to get the win . xxmaj benoit and xxmaj guerrero heated up early on by taking turns hammering first xxmaj spike and then xxmaj bubba xxmaj ray . a xxmaj german xxunk by xxmaj benoit to xxmaj bubba took the wind out of the xxmaj dudley brother . xxmaj spike tried to help his brother , but the referee restrained him while xxmaj benoit and xxmaj guerrero</td>\n",
              "      <td>pos</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>xxbos * ! ! - xxup spoilers - ! ! * \\n\\n xxmaj before i begin this , let me say that i have had both the advantages of seeing this movie on the big screen and of having seen the \" authorized xxmaj version \" of this movie , remade by xxmaj stephen xxmaj king , himself , in 1997 . \\n\\n xxmaj both advantages made me appreciate this version of \" the xxmaj shining , \" all the more . \\n\\n xxmaj also , let me say that xxmaj i 've read xxmaj mr . xxmaj king 's book , \" the xxmaj shining \" on many occasions over the years , and while i love the book and am a huge fan of his work , xxmaj stanley xxmaj kubrick 's retelling of this story is far more compelling … and xxup scary . \\n\\n xxmaj kubrick</td>\n",
              "      <td>pos</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>xxbos xxmaj titanic directed by xxmaj james xxmaj cameron presents a fictional love story on the historical setting of the xxmaj titanic . xxmaj the plot is simple , xxunk , or not for those who love plots that twist and turn and keep you in suspense . xxmaj the end of the movie can be figured out within minutes of the start of the film , but the love story is an interesting one , however . xxmaj kate xxmaj winslett is wonderful as xxmaj rose , an aristocratic young lady betrothed by xxmaj cal ( billy xxmaj zane ) . xxmaj early on the voyage xxmaj rose meets xxmaj jack ( leonardo dicaprio ) , a lower class artist on his way to xxmaj america after winning his ticket aboard xxmaj titanic in a poker game . xxmaj if he wants something , he goes and gets it</td>\n",
              "      <td>pos</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "learn = text_classifier_learner(dls_class, AWD_LSTM, drop_mult=0.5,\n",
        "                                metrics=accuracy).to_fp16()"
      ],
      "metadata": {
        "id": "Vr7Ms36FbQDB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "learn = learn.load_encoder('finetuned')"
      ],
      "metadata": {
        "id": "hB7MoGKubS9t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "learn.fit_one_cycle(1, 2e-2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "id": "6oOh9mbNbU-p",
        "outputId": "398a9f13-1e07-4050-ea21-bc3e76b054d1"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/fastai/callback/fp16.py:47: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  self.autocast,self.learn.scaler,self.scales = autocast(dtype=dtype),GradScaler(**self.kwargs),L()\n",
            "/usr/local/lib/python3.10/dist-packages/fastai/callback/fp16.py:47: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  self.autocast,self.learn.scaler,self.scales = autocast(dtype=dtype),GradScaler(**self.kwargs),L()\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.276680</td>\n",
              "      <td>0.218589</td>\n",
              "      <td>0.911680</td>\n",
              "      <td>01:24</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "learn.freeze_to(-2)\n",
        "learn.fit_one_cycle(1, slice(1e-2/(2.6**4),1e-2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "id": "fJbtJNdebZhU",
        "outputId": "d58b20cd-092e-408c-a4e4-3c5144ae8cc9"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/fastai/callback/fp16.py:47: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  self.autocast,self.learn.scaler,self.scales = autocast(dtype=dtype),GradScaler(**self.kwargs),L()\n",
            "/usr/local/lib/python3.10/dist-packages/fastai/callback/fp16.py:47: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  self.autocast,self.learn.scaler,self.scales = autocast(dtype=dtype),GradScaler(**self.kwargs),L()\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.241173</td>\n",
              "      <td>0.188449</td>\n",
              "      <td>0.926880</td>\n",
              "      <td>01:29</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "learn.freeze_to(-3)\n",
        "learn.fit_one_cycle(1, slice(5e-3/(2.6**4),5e-3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "id": "8JjGSXTtbeHV",
        "outputId": "a75860bc-7966-4e88-eff6-d2d2b70cbde3"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/fastai/callback/fp16.py:47: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  self.autocast,self.learn.scaler,self.scales = autocast(dtype=dtype),GradScaler(**self.kwargs),L()\n",
            "/usr/local/lib/python3.10/dist-packages/fastai/callback/fp16.py:47: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  self.autocast,self.learn.scaler,self.scales = autocast(dtype=dtype),GradScaler(**self.kwargs),L()\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.204052</td>\n",
              "      <td>0.164709</td>\n",
              "      <td>0.938720</td>\n",
              "      <td>01:36</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "learn.unfreeze()\n",
        "learn.fit_one_cycle(2, slice(1e-3/(2.6**4),1e-3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 201
        },
        "id": "JGqfdAQQbg3y",
        "outputId": "4f2218bc-90d6-4b81-93e2-895b7c9bfcd5"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/fastai/callback/fp16.py:47: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  self.autocast,self.learn.scaler,self.scales = autocast(dtype=dtype),GradScaler(**self.kwargs),L()\n",
            "/usr/local/lib/python3.10/dist-packages/fastai/callback/fp16.py:47: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  self.autocast,self.learn.scaler,self.scales = autocast(dtype=dtype),GradScaler(**self.kwargs),L()\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.163240</td>\n",
              "      <td>0.159841</td>\n",
              "      <td>0.940400</td>\n",
              "      <td>01:55</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.143213</td>\n",
              "      <td>0.159431</td>\n",
              "      <td>0.941480</td>\n",
              "      <td>01:55</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}